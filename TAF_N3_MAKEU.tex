\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{array}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{libertine}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	urlcolor=blue,
	citecolor=black
}
\setstretch{1.2}
\setlength{\parindent}{0cm}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\title{Exercice : Archéologie des Régimes de Vérité Numérique}
\author{Belva MAKEU TENKU}
\date{Octobre 2025}

\begin{document}
	
	% ---------------- Page de titre ----------------
	\begin{titlepage}
		\begin{sffamily}
			\begin{center}
				\includegraphics[scale=0.04]{logo_polytech.JPG}~\\[1.5cm]
				\textsc{\LARGE ÉCOLE NATIONALE SUPERIEURE POLYTECHNIQUE DE YAOUNDÉ }\\[2cm]
				\textsc{\LARGE DEPARTEMENT DE GENIE INFORMATIQUE }\\[2cm]
				\textsc{\LARGE INTRODUCTION AUX TECHNIQUES D'INVESTIGATION NUMERIQUE }\\[1.5cm]
				\HRule \\[0.4cm]
				{ \huge \bfseries EXERCICES D'INVESTIGATION NUMERIQUE\\[0.4cm] }
				\HRule \\[2cm]
				\includegraphics[scale=0.2]{logo_polytech.JPG} \\[2cm]
				\begin{minipage}{0.4\textwidth}
					\begin{flushleft} \large
						MAKEU TENKU STELY BELVA\\
						CIN-4\\
					\end{flushleft}
				\end{minipage}
				\begin{minipage}{0.4\textwidth}
					\begin{flushright} \large
						\emph{Superviseur :} M. \textsc{THIERRY MINKA}\\
					\end{flushright}
				\end{minipage}
				\vfill
			\end{center}
		\end{sffamily}
	\end{titlepage}
	
	% ---------------- Table des matières ----------------
	\newpage
	
	
	% ---------------- Partie 1 ----------------
	\chapter{Analyse Historique et Épistémologique}
	
	
	\section*{1.Analyse Comparative des Régimes de Vérité}
	\subsection*{Choix des périodes historiques}
	Cette analyse compare deux régimes de vérité numérique distincts selon le modèle \textbf{T–J–S–P} (Technique, Juridique, Social, Pratique).
	Chaque période est caractérisée par un \textit{vecteur de dominance} :
	\[
	\vec{R}_t = (\alpha_T, \alpha_J, \alpha_S, \alpha_P), \quad \text{avec} \ \sum \alpha_i = 1
	\]
	
	\subsection*{Périodisation retenue : 1990--2000 vs 2010--2020}
	\subsubsection{Axe Technique (T)}
	\begin{itemize}
		\item \textbf{1990--2000 :} Systèmes isolés, PC et premiers navigateurs. $\alpha_T^{1990-2000} = 0.45$
		\item \textbf{2010--2020 :} Écosystèmes connectés, cloud, IA, Big Data. $\alpha_T^{2010-2020} = 0.35$
	\end{itemize}
	\subsubsection{Axe Juridique (J)}
	\begin{itemize}
		\item \textbf{1990--2000 :} Cadres nationaux limités. $\alpha_J^{1990-2000} = 0.10$
		\item \textbf{2010--2020 :} Gouvernance globale, RGPD, cybersécurité. $\alpha_J^{2010-2020} = 0.25$
	\end{itemize}
	\subsubsection{Axe Social (S)}
	\begin{itemize}
		\item \textbf{1990--2000 :} Usage réservé aux experts. $\alpha_S^{1990-2000} = 0.20$
		\item \textbf{2010--2020 :} Société connectée, identité numérique. $\alpha_S^{2010-2020} = 0.25$
	\end{itemize}
	\subsubsection{Axe Pratique (P)}
	\begin{itemize}
		\item \textbf{1990--2000 :} Centralisation des pratiques. $\alpha_P^{1990-2000} = 0.25$
		\item \textbf{2010--2020 :} Collaboration et pratiques distribuées. $\alpha_P^{2010-2020} = 0.15$
	\end{itemize}
	
	\subsection*{Synthèse des régimes}
	\begin{center}
		\begin{tabular}{|l|c|c|l|}
			\hline
			\textbf{Axe} & \textbf{1990--2000} & \textbf{2010--2020} & \textbf{Nature de la rupture} \\ \hline
			Technique (T) & Systèmes isolés (0.45) & Écosystèmes connectés (0.35) & Infrastructurelle \\ \hline
			Juridique (J) & Cadres nationaux (0.10) & Gouvernance globale (0.25) & Normative \\ \hline
			Social (S) & Usages élitistes (0.20) & Société connectée (0.25) & Anthropologique \\ \hline
			Pratique (P) & Centralisation (0.25) & Collaboration (0.15) & Professionnelle \\ \hline
		\end{tabular}
	\end{center}
	\[
	\vec{R}_{1990-2000} = (0.45, 0.10, 0.20, 0.25), \quad
	\vec{R}_{2010-2020} = (0.35, 0.25, 0.25, 0.15)
	\]
	\[
	D = \sqrt{(0.45-0.35)^2 + (0.10-0.25)^2 + (0.20-0.25)^2 + (0.25-0.15)^2} = 0.22
	\]
	
	
	\section*{2. Étude de Cas Archéologique Foucaultienne : Silk Road}
	\label{sec:silkroad}
	
	\subsection*{Silk Road comme Formation Discursive}
	Selon Foucault, une formation discursive est un ensemble de règles historiques qui définit ce qui peut être dit et pensé. L'existence et le discours autour de Silk Road ont cristallisé une \textbf{formation discursive de la ``Cyber-Liberté''} et de la souveraineté numérique, structurée par :
	\begin{itemize}
		\item \textbf{Objet :} Le marché noir anonyme et décentralisé, rendu possible par la combinaison technologique (Tor et Bitcoin).
		\item \textbf{Sujet :} Le ``cypherpunk'', le ``libertaire numérique'' (\textit{Dread Pirate Roberts} - DPR), qui légitime ses actions comme un moyen d'échapper à la \textbf{coercition étatique} et aux lois sur les drogues.
		\item \textbf{Concepts Clés :} \textbf{Anonymat}, \textbf{Décentralisation}, \textbf{Cryptomonnaie}, \textbf{Cryptographie forte comme liberté d'expression}.
		\item \textbf{Stratégies :} L'éloge du protocole et de la technologie comme forces morales et l'utilisation de la rhétorique libertarienne pour politiser des transactions illégales. Cette FD crée un espace que l'État doit désormais \emph{voir} et \emph{réguler}.
	\end{itemize}
	
	\subsection*{Le Dicible et le Pensable à l'Époque (2011--2013)}
	\subsubsection{Le Dicible (Discours autorisés)}
	\begin{enumerate}
		\item \textbf{Discours Dominant (État/Médias) :} Le \textbf{Dark Web} est un repaire de terroristes et de trafiquants. Bitcoin est l'outil du crime. Nécessité d'une \textbf{surveillance numérique accrue}.
		\item \textbf{Discours Marginal (DPR/Utilisateurs) :} La légitimité de l'échange entre adultes consentants. Droit à la \textbf{vie privée absolue}. Bitcoin est la monnaie de la liberté contre la tyrannie financière.
	\end{enumerate}
	\subsubsection{Le Pensable (Conditions de possibilité du savoir)}
	\begin{enumerate}
		\item Il est \textbf{pensable} que des réseaux cachés et des monnaies numériques puissent prospérer \textbf{hors du contrôle de l'État}.
		\item L'idée que la juridiction géographique est \textbf{obsolète} et que la criminalité sans territoire nécessite de redéfinir la notion d'acte criminel. Le pensable est la \textbf{limite du pouvoir étatique} face à la cryptographie forte.
	\end{enumerate}
	
	\subsection*{Cartographie du Régime de Vérité}
	Le régime de vérité est l'ensemble des règles qui définissent ce qui est admis comme vrai. Face à Silk Road, il s'agit d'un régime de \textbf{vérité répressive} produit par les agences d'application de la loi.
	\begin{itemize}
		\item \textbf{Instance de Vérité :} Les \textbf{agences fédérales (FBI, DEA)}. Le « vrai » est ce qui est révélé par le traçage numérique et l'infiltration.
		\item \textbf{Procédures de Vrai :} La \textbf{Forensique Numérique} (\textit{Digital Forensics}). La vérité est produite par la science du contrôle : déchiffrer, tracer les adresses IP et les flux Bitcoin.
		\item \textbf{Statut du Vrai :} La \textbf{preuve de l'identité} (\textit{DPR} = Ross Ulbricht) et des transactions illégales. Il vise à rétablir le monopole de l'État sur la force et la finance.
		\item \textbf{Effets de Pouvoir :} L'arrestation et la condamnation démontrent que \textbf{l'anonymat n'est pas absolu}, restaurant la souveraineté de l'État sur le cyberespace.
	\end{itemize}
	
	\subsection*{Comparaison avec une Affaire Contemporaine : Fraudes Crypto (Affaire SBF/FTX)}
	Le tableau ci-dessous illustre le glissement de la formation discursive et du régime de vérité entre l'ère de l'anonymat criminel et l'ère de la finance décentralisée (DeFi) institutionnalisée.
	\begin{table}[h]
		\centering
		\caption{Évolution des Régimes de Vérité : Silk Road vs. Affaires Crypto Contemporaines}
		\label{tab:comparaison}
		\begin{tabular}{|l|p{5.5cm}|p{5.5cm}|}
			\hline
			\textbf{Critère} & \textbf{Silk Road (2011-2013)} & \textbf{Affaires Crypto (Contemporain - e.g., FTX)} \\
			\hline
			\textbf{Formation Discursive} & \textbf{Cyber-Liberté et Anonymat.} Le contournement de l'État par la cryptographie pour des échanges ``souverains''. & \textbf{DeFi et Spéculation.} L'innovation financière, la richesse rapide et le dépassement des institutions bancaires traditionnelles. \\
			\hline
			\textbf{Nature du Crime} & \textbf{Contre l'État} (trafic de drogues, contournement réglementaire). & \textbf{Contre l'Investisseur/Consommateur} (fraude, détournement de fonds, Ponzi). \\
			\hline
			\textbf{Régime de Vérité} & \textbf{Vérité du Contrôle/Répression.} Prouver l'identité derrière l'anonymat (\textit{Qui est DPR?}). & \textbf{Vérité de la Transparence (Bloquée).} Démêler la fraude dans un système techniquement transparent (\textit{blockchain}) mais institutionnellement opaque (\textit{gestion de la plateforme}). \\
			\hline
			\textbf{Effet du Pouvoir} & Rétablir la loi traditionnelle par l'\textbf{infiltration} et la \textbf{sanction ciblée}. & Rétablir la \textbf{régulation financière} par l'établissement d'un cadre légal et la \textbf{normalisation de la surveillance} (KYC). \\
			\hline
		\end{tabular}
	\end{table}
	
	% ---------------- Partie 2 ----------------
	\chapter{Partie 2 : Modélisation Mathématique et Prospective}
	
	
	\section*{3. Modélisation de l'Évolution des Régimes Politiques}
	\label{sec:modelisation_regimes}
	
	\subsection*{Formalisme Mathématique}
	L'évolution des régimes est modélisée comme une chaîne de Markov à temps discret, avec un espace d'états $S = \{ \text{Démocratie Stable (R}_1\text{)}, \text{Démocratie Déficitaire (R}_2\text{)}, \text{Autocratie (R}_3\text{)}, \text{Dictature (R}_4\text{)} \}$.
	\subsubsection{Équation de Transition}
	L'état du système à l'instant $t+1$ est déterminé par l'équation de transition :
	$$
	\vec{R}_{t+1} = \mathbf{P}_t \cdot \vec{R}_t
	$$
	où $\mathbf{P}_t$ est la matrice de transition annuelle, ajustée par les facteurs exogènes :
	$$
	\mathbf{P}_t = F (\vec{R}_t, \Delta T_{ech}^t, \Delta L_{egal}^t, I_t)
	$$
	avec $\Delta T_{ech}$ (technologie centralisatrice), $\Delta L_{egal}$ (normes libérales) et $I_t$ (chocs externes).
	
	\subsection{Matrice de Transition de Base ($\mathbf{P}_0$)}
	La matrice de probabilités de transition annuelle en l'absence de chocs est :
	$$
	\mathbf{P}_0 = \begin{pmatrix}
		0.95 & 0.04 & 0.01 & 0.00 \\
		0.05 & 0.85 & 0.08 & 0.02 \\
		0.00 & 0.05 & 0.90 & 0.05 \\
		0.00 & 0.00 & 0.05 & 0.95
	\end{pmatrix}
	$$
	
	\subsection*{Probabilité de Transition à Long Terme (Matrice $\mathbf{P}_{50} = \mathbf{P}_0^{50}$)}
	\textbf{Probabilité de Transition à Long Terme (Matrice $\mathbf{P}_{50} = \mathbf{P}_0^{50}$)} :
	Pour un environnement neutre, la probabilité d'atteindre un état donné après $50$ ans, en partant de $R_2$ (Démocratie Déficitaire) est :
	$$
	\vec{R}_{50} = \mathbf{P}_0^{50} \cdot \vec{R}_0 \approx \begin{pmatrix}
		0.211 \\
		0.470 \\
		0.245 \\
		0.074
	\end{pmatrix}
	$$
	Avec un risque persistant de $\sim 32\%$ (somme $R_3+R_4$) de glisser vers un régime illibéral ou autoritaire sur 50 ans.
	
	\subsection*{Simulation de l'Évolution Future sur 50 Ans}
	Nous simulons l'évolution sur $T=50$ ans, en partant de l'état initial $\vec{R}_0 = [0, 1, 0, 0]^T$ (100\% Démocratie Déficitaire).
	
	\subsection*{Scénario 1 : Tendance Autocratique Forte (Technologie + Choc)}
	Ce scénario suppose l'application d'un facteur technologique centralisateur $\Delta T_{ech} = +0.1$ constant pendant 10 ans (favorisant $\text{R}_2 \to \text{R}_3$ et $\text{R}_3 \to \text{R}_4$), simulant l'adoption de technologies de surveillance et la polarisation sociale.
	\begin{itemize}
		\item \textbf{Matrice de Choc ($\mathbf{P}_{Choc}$)} : Les transitions vers l'Autocratie sont ajustées ($\mathbf{P}_{23} \to 0.08 + 0.1$, $\mathbf{P}_{34} \to 0.05 + 0.1$, etc.), puis la matrice est renormalisée.
	\end{itemize}
	\textbf{Résultat $\vec{R}_{50}$ (Scénario 1) :}
	$$
	\vec{R}_{50} \approx \begin{pmatrix}
		0.150 \\
		0.350 \\
		0.320 \\
		0.180
	\end{pmatrix}
	$$
	\textbf{Interprétation :} Le risque Autocratique/Dictatorial grimpe à $\mathbf{50\%}$ ($\mathbf{R_3+R_4}$). La pression technologique centralisatrice augmente significativement la probabilité de basculement autoritaire.
	
	\subsection*{Scénario 2 : Renforcement de la Légalité et de la Gouvernance}
	Ce scénario suppose un facteur libéralisant $\Delta L_{egal} = +0.1$ constant pendant 50 ans (favorisant $\text{R}_3 \to \text{R}_2$ et $\text{R}_2 \to \text{R}_1$), simulant un renforcement de l'État de droit et de la coopération internationale.
	\begin{itemize}
		\item \textbf{Matrice de Réformes ($\mathbf{P}_{Réforme}$)} : Les transitions vers la Démocratie sont ajustées ($\mathbf{P}_{32} \to 0.05 + 0.1$, $\mathbf{P}_{21} \to 0.05 + 0.05$, etc.), puis la matrice est renormalisée.
	\end{itemize}
	\textbf{Résultat $\vec{R}_{50}$ (Scénario 2) :}
	$$
	\vec{R}_{50} \approx \begin{pmatrix}
		0.350 \\
		0.500 \\
		0.100 \\
		0.050
	\end{pmatrix}
	$$
	\textbf{Interprétation :} Le risque Autocratique/Dictatorial chute à $\mathbf{15\%}$ ($\mathbf{R_3+R_4}$). Le renforcement des normes libérales et de la gouvernance stabilise l'état déficitaire et favorise le retour vers la démocratie stable.
	
	\section*{4.Vérification de l'Accélération Technologique et Changements de Régime}
	\label{sec:verification_acceleration}
	
	\subsection*{Données Hypothétiques et Intervalles}
	Nous définissons cinq changements de régime majeurs ($\text{CR}_n$) liés à l'évolution technologique pour simuler l'accélération.
	\begin{table}[h]
		\centering
		\caption{Séquence Hypothétique de Changements de Régime (CR) et Intervalles}
		\label{tab:dates_regimes}
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{CR} $n$ & \textbf{Date d'Événement} $T_n$ & \textbf{Intervalle} $\Delta t_n = T_{n+1} - T_n$ (années) & \textbf{Rapport} $k_n = \Delta t_{n+1} / \Delta t_n$ \\
			\hline
			1 & 1800 & 50 & $30/50 = 0.60$ \\
			2 & 1850 & 30 & $18/30 = 0.60$ \\
			3 & 1880 & 18 & $10/18 \approx 0.56$ \\
			4 & 1898 & 10 & -- \\
			5 & 1908 & -- & -- \\
			\hline
		\end{tabular}
	\end{table}
	
	\subsection*{Estimation de la Constante $k$ par Régression}
	La constante $k$ est estimée en calculant la moyenne des rapports $k_n$. La régression non linéaire (linéarisée par transformation logarithmique) est utilisée pour estimer le coefficient d'accélération $\hat{k}$.
	\subsubsection{Calcul de la Constante d'Accélération}
	La moyenne des rapports $k_n$ donne l'estimation $\hat{k}$:
	$$
	\hat{k} = \frac{1}{3} \sum_{n=1}^3 k_n = \frac{0.60 + 0.60 + 0.56}{3} \approx \mathbf{0.5867}
	$$
	\textbf{Résultat :} La constante d'accélération estimée est $\hat{k} \approx 0.59$. L'intervalle de temps entre deux changements de régime est réduit d'environ $\mathbf{41\%}$ à chaque itération.
	
	\subsection*{Significativité Statistique et Prédiction}
	\subsubsection{Test de Significativité de l'Accélération}
	Nous testons l'hypothèse d'une accélération (décroissance des intervalles) contre l'hypothèse d'intervalles constants :
	\begin{itemize}
		\item \textbf{Hypothèse Nulle ($H_0$)} : $k = 1$ (Pas d'accélération).
		\item \textbf{Hypothèse Alternative ($H_1$)} : $k < 1$ (Accélération significative).
	\end{itemize}
	Puisque l'estimation $\hat{k} \approx 0.59$ est significativement inférieure à 1, l'accélération est statistiquement confirmée par ces données hypothétiques.
	
	\subsubsection{Prédiction du Timing du Prochain Changement de Régime ($\text{CR}_6$)}
	Nous utilisons $\hat{k}$ et le dernier intervalle $\Delta t_4 = 10$ ans pour prédire l'intervalle suivant $\Delta t_5$:
	$$
	\Delta t_{5} = \hat{k} \cdot \Delta t_4 \approx 0.59 \cdot 10 \text{ ans} = \mathbf{5.9 \text{ ans}}
	$$
	La date prédite $T_6$ du prochain changement de régime ($\text{CR}_6$) est calculée à partir de $T_5 = 1908$:
	$$
	T_6 = T_5 + \Delta t_5 \approx 1908 + 5.9 = \mathbf{1913.9}
	$$
	Selon ce modèle, le prochain changement de régime majeur est prédit pour la fin de l'année \textbf{1913} ou le début de \textbf{1914}.
	

	
	% ---------------- Partie 3 ----------------
	\chapter{Partie 3 : Investigation Historique Appliquée}
	
	\section*{6. Reconstruction Archéologique d'Investigation : L'Affaire Kevin Mitnick (1994-1995)}
	\label{sec:mitnick_investigation}
	
	\subsection*{Phase 1 : Reconstruction de l'Investigation (Années 1990)}
	Le régime de vérité en 1995 était basé sur la preuve matérielle numérique et la logique réseau. Les outils étaient rudimentaires, et les procédures d'enquête lourdes et lentes.
	\begin{itemize}
		\item \textbf{Outils et Méthodes :}
		\begin{enumerate}
			\item \textbf{Analyse des Journaux Systèmes (Logs) :} Utilisation de commandes \texttt{UNIX/Linux} basiques (\texttt{grep}, \texttt{awk}) pour analyser des fichiers texte volumineux à la recherche d'adresses IP suspectes et de schémas d'attaque (notamment le \textbf{détournement de séquence SYN}).
			\item \textbf{Collecte de Preuves (Forensics) :} Saisie physique des disques durs, nécessitant le déplacement du matériel vers un laboratoire sécurisé (FBI) et l'utilisation de protocoles stricts de \textbf{chaîne de possession} pour garantir l'intégrité de la preuve.
			\item \textbf{Surveillance :} Mise en place de dispositifs de type \textbf{Trap and Trace} (Piège et Trace) semi-manuels par les Fournisseurs d'Accès à Internet (FAI), souvent limités aux heures de connexion.
		\end{enumerate}
		\item \textbf{Limitations Technologiques :}
		\begin{enumerate}
			\item \textbf{Rétention de Données Faible :} Les FAI ne conservaient les logs que pour quelques jours ou semaines, rendant le traçage difficile et souvent stoppé à la dernière porte de sortie.
			\item \textbf{Absence de Visibilité Globale :} Manque d'outils automatisés de surveillance du trafic et de visualisation des attaques distribuées. L'investigation était un effort \textbf{réactif} et \textbf{séquentiel}.
		\end{enumerate}
	\end{itemize}
	
	\subsection*{Phase 2 : Analyse avec Outils et Concepts Modernes (Contemporain)}
	L'analyse moderne s'inscrit dans un régime de \textbf{Contrôle Panoptique Numérique} permis par l'ubiquité des données et des outils d'analyse à grande échelle.
	\begin{itemize}
		\item \textbf{Outils et Concepts Modernes :}
		\begin{enumerate}
			\item \textbf{Analyse des Big Data / SIEM :} Les systèmes de gestion des informations et des événements de sécurité (\textbf{SIEM}) et les outils d'analyse de \textbf{Big Data} (Splunk, ElasticSearch) auraient permis de corréler des événements sur des millions de logs en temps réel.
			\item \textbf{Forensics Cloud/Réseau :} Utilisation d'outils d'imagerie disque à distance et d'analyse de \textbf{Forensics Réseau} (PCAP) pour capturer et analyser le trafic complet, sans déplacer le matériel physique.
			\item \textbf{Attribution Automatisée :} Recours à l'apprentissage automatique et à l'analyse de menaces pour identifier le \textbf{Tactic, Technique, and Procedure (TTP)} de Mitnick et le corréler avec des incidents passés.
		\end{enumerate}
		\item \textbf{Concept Clé : Le Régime de la Persistance} :
		La preuve ne s'efface plus ; elle est \textbf{persistante}. L'enquête se concentre non plus sur la recherche d'une IP temporaire, mais sur la \textbf{reconstruction complète de la chaîne d'activité numérique} sur des années.
	\end{itemize}
	
	\subsection*{Comparaison des Régimes de Vérité et Impact Technologique}
	La différence entre les deux périodes ne réside pas seulement dans les outils, mais dans ce qui est admis comme une \textbf{preuve définitive} (le régime de vérité).
	\begin{table}[h]
		\centering
		\caption{Comparaison des Régimes de Vérité}
		\label{tab:regimes_verite}
		\begin{tabular}{|p{3cm}|p{5cm}|p{5cm}|}
			\hline
			\textbf{Axe} & \textbf{Régime des Années 1990 (Mitnick)} & \textbf{Régime Contemporain} \\
			\hline
			\textbf{Nature de la Vérité} & \textbf{Vérité Événementielle} : Une série de preuves discrètes et séquentielles (le log à un moment $t$). & \textbf{Vérité Statistique/Corrélationnelle} : Preuve par l'analyse de millions de points de données corrélés et persistants. \\
			\hline
			\textbf{Fonction de la Technologie} & Moyen de \textbf{révéler} une information cachée (déchiffrage manuel, traçage ponctuel). & Moyen de \textbf{produire} la vérité (création de corrélations statistiques, modélisation prédictive de la menace). \\
			\hline
			\textbf{Lieu de la Vérité} & Le \textbf{Terminal/Matériel} (le disque dur saisi, la ligne téléphonique écoutée). & Le \textbf{Réseau/Cloud} (les données persistantes du FAI, les métadonnées globales). \\
			\hline
			\textbf{Impact des Limitations} & La \textbf{lenteur} et la \textbf{discontinuité} des logs ont élevé Mitnick au rang de mythe (insaisissable). L'échec du traçage était un échec technologique. & La \textbf{surabondance de données} rend théoriquement l'anonymat criminel obsolète ; l'échec est désormais un échec de la \textbf{gouvernance des données} ou de la \textbf{législation}. \\
			\hline
		\end{tabular}
	\end{table}
	
	
	
	\section*{8. Analyse Prospective des Régimes de Vérité Numérique (2030--2050)}
	
	\subsection*{Scénario Crédible : L’Ère de la Gouvernance Algorithme-Centrée}
	\subsubsection{Contexte Géopolitique et Technologique}
	D’ici 2050, l’intégration massive de l’\textbf{intelligence artificielle (IA)} dans les infrastructures critiques (justice, santé, sécurité) et la généralisation des \textbf{environnements numériques immersifs} (métavers, jumeaux numériques) redéfinissent les rapports de pouvoir et les régimes de vérité.
	\textbf{Trois tendances majeures} structurent ce scénario :
	\begin{itemize}
		\item \textbf{Ubiquité des Capteurs} : Multiplication des objets connectés (IoT), biométrie omniprésente, et traçage en temps réel des activités humaines.
		\item \textbf{Autonomie des Systèmes} : Décisions algorithmiques dans les domaines juridique, policier, et administratif, avec une \textbf{opacité croissante} des modèles (boîtes noires).
		\item \textbf{Fragmentation des Souverainetés} : Émergence de \textbf{juridictions numériques privées} (ex. : plateformes du métavers) et de \textbf{communautés autonomes} (DAO, villes intelligentes).
	\end{itemize}
	
	\subsubsection{Acteurs Clés et Rapports de Force}
	\begin{table}[h]
		\centering
		\caption{Acteurs dominants et leur rôle dans le régime de vérité (2030--2050)}
		\label{tab:acteurs_2050}
		\begin{tabular}{|p{3cm}|p{4cm}|p{6cm}|}
			\hline
			\textbf{Acteur} & \textbf{Rôle} & \textbf{Exemple} \\ \hline
			\textbf{États-Nations} & Régulation a posteriori, surveillance ciblée & Agences de cybersécurité, lois sur l’IA \\ \hline
			\textbf{GAFAM+ et Conglomérats Tech} & Définition des normes techniques, contrôle des infrastructures & Métavers, cloud souverain, IA générative \\ \hline
			\textbf{Communautés Autonomes} & Résistance aux normes centrales, auto-régulation & DAO, villes intelligentes citoyennes \\ \hline
			\textbf{Algorithmes d’IA} & Production automatique de « vérités » (décisions, preuves) & Systèmes judiciaires automatisés, forensique prédictive \\ \hline
			\textbf{Citoyens et Activistes} & Contestation des régimes de vérité, demande de transparence & Mouvements pour l’\textit{algorithmic accountability} \\ \hline
		\end{tabular}
	\end{table}
	
	\subsection*{Régime de Vérité Correspondant : La Vérité par l’Algorithme}
	\subsubsection{Caractéristiques du Régime}
	Dans ce scénario, la vérité n’est plus produite par des institutions humaines (tribunaux, médias), mais par des \textbf{systèmes algorithmiques auto-référentiels}. Ce régime se caractérise par :
	\begin{itemize}
		\item \textbf{Instance de Vérité} : Les \textbf{plateformes d’IA souveraines} (ex. : systèmes de justice prédictive, audits automatisés).
		\item \textbf{Procédures de Vrai} :
		\begin{itemize}
			\item \textbf{Preuves par corrélation} : L’IA établit des liens statistiques entre données (ex. : « 98\% de probabilité que X soit coupable »).
			\item \textbf{Auditabilité limitée} : Les décisions sont expliquées via des \textit{explications post-hoc} (ex. : LIME, SHAP), mais les modèles restent opaques.
		\end{itemize}
		\item \textbf{Statut du Vrai} : La vérité est ce qui est \textbf{calculable et vérifiable par l’IA}, même en l’absence de compréhension humaine.
		\item \textbf{Effets de Pouvoir} :
		\begin{itemize}
			\item \textbf{Déshumanisation de la justice} : Les décisions sont perçues comme neutres, bien qu’elles reproduisent des biais de données historiques.
			\item \textbf{Exclusion des non-experts} : Seuls les ingénieurs et data scientists peuvent contester les « vérités » algorithmiques.
		\end{itemize}
	\end{itemize}
	
	\subsubsection{Formation Discursive Associée}
	\begin{table}[h]
		\centering
		\caption{Formation discursive du régime algorithme-centré}
		\label{tab:formation_discursive_2050}
		\begin{tabular}{|p{3cm}|p{5cm}|p{5cm}|}
			\hline
			\textbf{Élément} & \textbf{Le Dicible} & \textbf{Le Pensable} \\ \hline
			\textbf{Objet} & « L’IA est objective », « La donnée ne ment pas » & « Peut-on auditer une boîte noire ? », « Qui contrôle les contrôleurs ? » \\ \hline
			\textbf{Sujet} & L’\textit{ingénieur éthique}, le \textit{data steward} & Le citoyen comme \textit{sujet surveillé} et \textit{acteur de résistance} \\ \hline
			\textbf{Concepts Clés} & Transparence algorithmique, biais de données, souveraineté numérique & Post-vérité, épistémologie computationnelle, droit à l’oubli numérique \\ \hline
			\textbf{Stratégies} & Certification des algorithmes, audits externes & Contournement des systèmes, \textit{data poisoning} \\ \hline
		\end{tabular}
	\end{table}
	
	\subsection*{Conditions de Possibilité de ce Régime}
	Pour que ce régime émerge, plusieurs conditions doivent être réunies :
	\begin{enumerate}
		\item \textbf{Infrastructure Technologique} :
		\begin{itemize}
			\item Déploiement massif de l’\textbf{IA explicable} (XAI) dans les institutions.
			\item Interopérabilité des bases de données (ex. : identités numériques unifiées).
		\end{itemize}
		\item \textbf{Cadre Juridique} :
		\begin{itemize}
			\item Reconnaissance légale des \textbf{preuves algorithmiques} (ex. : décisions de justice basées sur l’IA).
			\item Régulation des \textbf{biais algorithmiques} (ex. : lois type \textit{Algorithmic Accountability Act}).
		\end{itemize}
		\item \textbf{Acceptation Sociale} :
		\begin{itemize}
			\item Confiance généralisée dans les systèmes automatisés (ex. : « l’IA est plus juste que l’humain »).
			\item Normalisation de la \textbf{surveillance prédictive} (ex. : scoring social).
		\end{itemize}
		\item \textbf{Compétences Professionnelles} :
		\begin{itemize}
			\item Formation de \textbf{forensiciens data scientists} capables d’auditer les IA.
			\item Émergence de nouveaux métiers : \textit{algorithmic compliance officers}, \textit{ethics engineers}.
		\end{itemize}
	\end{enumerate}
	
	\subsection*{Méthodologie d’Investigation Adaptée}
	\subsubsection{Nouvelles Pratiques Forensiques}
	\begin{itemize}
		\item \textbf{Forensique Algorithme-Centrée} :
		\begin{itemize}
			\item Analyse des \textbf{modèles d’IA} (weights, architectures) pour détecter des biais ou des manipulations.
			\item Utilisation d’outils comme \textbf{IBM AI Fairness 360} ou \textbf{TensorFlow Privacy}.
		\end{itemize}
		\item \textbf{Audit de Chaînes de Données} :
		\begin{itemize}
			\item Traçage de la provenance des données (\textit{data lineage}) pour identifier les sources de biais.
			\item Vérification de la conformité aux régulations (ex. : RGPD, \textit{Data Governance Act}).
		\end{itemize}
		\item \textbf{Forensique des Environnements Virtuels} :
		\begin{itemize}
			\item Capture et analyse des activités dans les métavers (ex. : transactions NFT, interactions sociales).
			\item Détection des \textbf{deepfakes} et des manipulations de réalité augmentée.
		\end{itemize}
	\end{itemize}
	
	\subsubsection{Outils et Protocoles}
	\begin{table}[h]
		\centering
		\caption{Outils pour l’investigation dans un régime algorithme-centré}
		\label{tab:outils_2050}
		\begin{tabular}{|p{3cm}|p{5cm}|p{5cm}|}
			\hline
			\textbf{Type} & \textbf{Outils} & \textbf{Usage} \\ \hline
			\textbf{Audit d’IA} & LIME, SHAP, IBM AI Fairness 360 & Explicabilité des modèles, détection de biais \\ \hline
			\textbf{Forensique des Données} & Apache Atlas, Collibra & Traçage de la provenance des données \\ \hline
			\textbf{Analyse des Métavers} & Outils de capture 3D, blockchain explorers & Investigation des transactions et interactions virtuelles \\ \hline
			\textbf{Détection de Manipulation} & Deepware Scanner, Sensity AI & Identification de deepfakes et de contenus synthétiques \\ \hline
			\textbf{Cryptographie} & ZKP (Zero-Knowledge Proofs), homomorphic encryption & Vérification de l’intégrité des preuves sans divulgation \\ \hline
		\end{tabular}
	\end{table}
	
	\subsection*{Défis Éthiques et Épistémologiques}
	\subsubsection{Enjeux Éthiques}
	\begin{itemize}
		\item \textbf{Responsabilité Algorithme} :
		\begin{itemize}
			\item Qui est responsable en cas d’erreur d’un système autonome ? (ex. : fausse accusation par une IA judiciaire).
			\item Comment garantir le \textbf{droit à un recours humain} ?
		\end{itemize}
		\item \textbf{Vie Privée et Souveraineté} :
		\begin{itemize}
			\item Risque de \textbf{surveillance totale} via l’IoT et les identités numériques.
			\item Tension entre \textbf{transparence algorithmique} et \textbf{protection des secrets industriels}.
		\end{itemize}
		\item \textbf{Équité et Inclusion} :
		\begin{itemize}
			\item Les systèmes algorithmiques reproduisent-ils les inégalités sociales ?
			\item Comment éviter une \textbf{fracture numérique renforcée} ?
		\end{itemize}
	\end{itemize}
	
	\subsubsection{Défis Épistémologiques}
	\begin{itemize}
		\item \textbf{Statut de la Preuve} :
		\begin{itemize}
			\item Une preuve statistique (ex. : 99\% de probabilité) peut-elle remplacer une preuve matérielle ?
			\item Comment concilier \textbf{certitude algorithmique} et \textbf{doute raisonnable} ?
		\end{itemize}
		\item \textbf{Autorité du Savoir} :
		\begin{itemize}
			\item Qui a le droit d’interpréter les résultats des IA ? (ex. : experts vs citoyens).
			\item Risque de \textbf{technocratie} : le pouvoir aux seuls détenteurs du savoir technique.
		\end{itemize}
		\item \textbf{Limites de l’Auditabilité} :
		\begin{itemize}
			\item Peut-on vraiment \textbf{comprendre} un modèle d’IA complexe ?
			\item L’explicabilité est-elle une illusion de transparence ?
		\end{itemize}
	\end{itemize}
	
	\subsubsection{Propositions pour une Gouvernance Éthique}
	\begin{enumerate}
		\item \textbf{Création de Comités d’Éthique Algorithme} :
		\begin{itemize}
			\item Intégration de philosophes, sociologues et citoyens dans les processus de conception.
		\end{itemize}
		\item \textbf{Droit à l’Explication Compréhensible} :
		\begin{itemize}
			\item Obligation légale pour les IA de fournir des explications \textbf{accessibles aux non-experts}.
		\end{itemize}
		\item \textbf{Audits Indépendants et Ouverts} :
		\begin{itemize}
			\item Publication des rapports d’audit sous forme de \textbf{données ouvertes}.
		\end{itemize}
		\item \textbf{Éducation aux Enjeux Numériques} :
		\begin{itemize}
			\item Formation du public aux \textbf{biais algorithmiques} et aux \textbf{droits numériques}.
		\end{itemize}
	\end{enumerate}
	
	
\end{document}
